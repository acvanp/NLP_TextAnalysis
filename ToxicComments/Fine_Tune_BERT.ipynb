{"metadata":{"accelerator":"GPU","colab":{"name":"Fine-tuning BERT (and friends) for multi-label text classification.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"091f8220f33241f288faa0612853585f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6111a73e684a47769bda7183a836ee91","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65","value":3}},"1045bb16e3694410898a73cf1b848917":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbba60f793c14100934a268063f63d26","placeholder":"​","style":"IPY_MODEL_cd3570ddf67541d7818d97e236c54e54","value":" 3/3 [00:00&lt;00:00, 75.93it/s]"}},"308fa6a7348140ec981a8d6c7d31f346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5080d322a8034924b652b379c04667ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6111a73e684a47769bda7183a836ee91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1899a0c4b144d7a5e6599f8afb8b65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bc92587e35443488445e7521fbd0a13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5080d322a8034924b652b379c04667ed","placeholder":"​","style":"IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f","value":"100%"}},"9a1aa9f2cc29473f9f8e5459d2641e76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bc92587e35443488445e7521fbd0a13","IPY_MODEL_091f8220f33241f288faa0612853585f","IPY_MODEL_1045bb16e3694410898a73cf1b848917"],"layout":"IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"}},"bbba60f793c14100934a268063f63d26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb95e545fbdd4e99903bf634df694c9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd3570ddf67541d7818d97e236c54e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning BERT (and friends) for multi-label text classification\n\nIn this notebook, we are going to fine-tune BERT to predict one or more labels for a given piece of text. Note that this notebook illustrates how to fine-tune a bert-base-uncased model, but you can also fine-tune a RoBERTa, DeBERTa, DistilBERT, CANINE, ... checkpoint in the same way. \n\nAll of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n\n\n\n## Set-up environment\n\nFirst, we install the libraries which we'll use: HuggingFace Transformers and Datasets.","metadata":{"id":"kLB3I4FKZ5Lr"}},{"cell_type":"code","source":"%pip install -q transformers datasets","metadata":{"id":"4wxY3x-ZZz8h","execution":{"iopub.status.busy":"2023-05-14T02:42:49.051919Z","iopub.execute_input":"2023-05-14T02:42:49.052320Z","iopub.status.idle":"2023-05-14T02:43:00.804120Z","shell.execute_reply.started":"2023-05-14T02:42:49.052288Z","shell.execute_reply":"2023-05-14T02:43:00.802826Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load dataset\n\nNext, let's download a multi-label text classification dataset from the [hub](https://huggingface.co/).\n\nAt the time of writing, I picked a random one as follows:   \n\n* first, go to the \"datasets\" tab on huggingface.co\n* next, select the \"multi-label-classification\" tag on the left as well as the the \"1k<10k\" tag (fo find a relatively small dataset).\n\nNote that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n\n","metadata":{"id":"bIH9NP0MZ6-O"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom transformers import EvalPrediction\nimport torch\nimport pandas as pd\nfrom ast import literal_eval    \nfrom datetime import datetime\nimport datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["9a1aa9f2cc29473f9f8e5459d2641e76","308fa6a7348140ec981a8d6c7d31f346","8bc92587e35443488445e7521fbd0a13","091f8220f33241f288faa0612853585f","1045bb16e3694410898a73cf1b848917","cb95e545fbdd4e99903bf634df694c9f","5080d322a8034924b652b379c04667ed","8b1899a0c4b144d7a5e6599f8afb8b65","6111a73e684a47769bda7183a836ee91","cd3570ddf67541d7818d97e236c54e54","bbba60f793c14100934a268063f63d26"]},"id":"sd1LiXGjZ420","outputId":"1b5783cd-0e4e-4c92-c67c-57b9288f2381","execution":{"iopub.status.busy":"2023-05-14T02:43:00.807126Z","iopub.execute_input":"2023-05-14T02:43:00.807788Z","iopub.status.idle":"2023-05-14T02:43:00.816611Z","shell.execute_reply.started":"2023-05-14T02:43:00.807747Z","shell.execute_reply":"2023-05-14T02:43:00.815428Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"level_selection = 'product'#'subcat'#'cat'\n#dir(datasets)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:00.818212Z","iopub.execute_input":"2023-05-14T02:43:00.818782Z","iopub.status.idle":"2023-05-14T02:43:00.828799Z","shell.execute_reply.started":"2023-05-14T02:43:00.818749Z","shell.execute_reply":"2023-05-14T02:43:00.827614Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df_train_raw = pd.read_csv('/kaggle/input/cleaned-toxic-comments/train_preprocessed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:00.832404Z","iopub.execute_input":"2023-05-14T02:43:00.832757Z","iopub.status.idle":"2023-05-14T02:43:01.659847Z","shell.execute_reply.started":"2023-05-14T02:43:00.832730Z","shell.execute_reply":"2023-05-14T02:43:01.658675Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# less toxic gets stack on top of more toxic and less toxic gets a 0 target, more toxic is a 1 target\ndf_train = df_train_raw.copy()\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:01.661385Z","iopub.execute_input":"2023-05-14T02:43:01.661960Z","iopub.status.idle":"2023-05-14T02:43:01.710132Z","shell.execute_reply.started":"2023-05-14T02:43:01.661923Z","shell.execute_reply":"2023-05-14T02:43:01.709076Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"                                             comment_text                id  \\\n0       explanation why the edits made under my userna...  0000997932d777bf   \n1       d aww  he matches this background colour i m s...  000103f0d9cfb60f   \n2       hey man  i m really not trying to edit war  it...  000113f07ec002fd   \n3         more i can t make any real suggestions on im...  0001b41b1c6bb37e   \n4       you  sir  are my hero  any chance you remember...  0001d958c54c6e35   \n...                                                   ...               ...   \n159566   and for the second time of asking  when your ...  ffe987279560d7ff   \n159567  you should be ashamed of yourself that is a ho...  ffea4adeee384e90   \n159568  spitzer umm  theres no actual article for pros...  ffee36eab5c267c9   \n159569  and it looks like it was actually you who put ...  fff125370e4aaaf3   \n159570    and i really don t think you understand i ca...  fff46fc426af1f9a   \n\n        identity_hate  insult  obscene    set  severe_toxic  threat  toxic  \\\n0                 0.0     0.0      0.0  train           0.0     0.0    0.0   \n1                 0.0     0.0      0.0  train           0.0     0.0    0.0   \n2                 0.0     0.0      0.0  train           0.0     0.0    0.0   \n3                 0.0     0.0      0.0  train           0.0     0.0    0.0   \n4                 0.0     0.0      0.0  train           0.0     0.0    0.0   \n...               ...     ...      ...    ...           ...     ...    ...   \n159566            0.0     0.0      0.0  train           0.0     0.0    0.0   \n159567            0.0     0.0      0.0  train           0.0     0.0    0.0   \n159568            0.0     0.0      0.0  train           0.0     0.0    0.0   \n159569            0.0     0.0      0.0  train           0.0     0.0    0.0   \n159570            0.0     0.0      0.0  train           0.0     0.0    0.0   \n\n        toxicity  \n0            0.0  \n1            0.0  \n2            0.0  \n3            0.0  \n4            0.0  \n...          ...  \n159566       0.0  \n159567       0.0  \n159568       0.0  \n159569       0.0  \n159570       0.0  \n\n[159571 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>id</th>\n      <th>identity_hate</th>\n      <th>insult</th>\n      <th>obscene</th>\n      <th>set</th>\n      <th>severe_toxic</th>\n      <th>threat</th>\n      <th>toxic</th>\n      <th>toxicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>explanation why the edits made under my userna...</td>\n      <td>0000997932d777bf</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d aww  he matches this background colour i m s...</td>\n      <td>000103f0d9cfb60f</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey man  i m really not trying to edit war  it...</td>\n      <td>000113f07ec002fd</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>more i can t make any real suggestions on im...</td>\n      <td>0001b41b1c6bb37e</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you  sir  are my hero  any chance you remember...</td>\n      <td>0001d958c54c6e35</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>and for the second time of asking  when your ...</td>\n      <td>ffe987279560d7ff</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>you should be ashamed of yourself that is a ho...</td>\n      <td>ffea4adeee384e90</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>spitzer umm  theres no actual article for pros...</td>\n      <td>ffee36eab5c267c9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>and it looks like it was actually you who put ...</td>\n      <td>fff125370e4aaaf3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>and i really don t think you understand i ca...</td>\n      <td>fff46fc426af1f9a</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train = df_train.sample(frac=1).reset_index(drop=True)\n#df_train = df_train.iloc[:300000,:]# shrink down the training data so training doesn't take so long\ndf_val = df_train.iloc[:1000,:]\ntest_all = df_train.iloc[1000:10000,:]\ndf_train = df_train.iloc[10000:,:]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:01.714647Z","iopub.execute_input":"2023-05-14T02:43:01.715080Z","iopub.status.idle":"2023-05-14T02:43:01.778206Z","shell.execute_reply.started":"2023-05-14T02:43:01.715045Z","shell.execute_reply":"2023-05-14T02:43:01.777122Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:01.779827Z","iopub.execute_input":"2023-05-14T02:43:01.780384Z","iopub.status.idle":"2023-05-14T02:43:02.275128Z","shell.execute_reply.started":"2023-05-14T02:43:01.780351Z","shell.execute_reply":"2023-05-14T02:43:02.274200Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f80755a2dfa4514bb8a93ac5ee97e24"}},"metadata":{}}]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:02.278191Z","iopub.execute_input":"2023-05-14T02:43:02.278944Z","iopub.status.idle":"2023-05-14T02:43:02.293573Z","shell.execute_reply.started":"2023-05-14T02:43:02.278905Z","shell.execute_reply":"2023-05-14T02:43:02.292533Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"Index(['comment_text', 'id', 'identity_hate', 'insult', 'obscene', 'set',\n       'severe_toxic', 'threat', 'toxic', 'toxicity'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"targets = ['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']\ngrouping = {k:v for k,v in zip(targets, range(len(targets)))}\ntrain_dict = []\ntest_dict = []\nval_dict = []\nfor d, f in zip([train_dict, test_dict, val_dict], [df_train, test_all, df_val]):\n    for row in f.index:\n        target_row = f[targets].loc[row].tolist()                       \n        temp = {k:int(v) for k,v in zip(targets, target_row)}\n        temp['text'] = f.comment_text[row]\n        temp['ID'] = row\n        d.append(temp)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:43:02.296953Z","iopub.execute_input":"2023-05-14T02:43:02.297671Z","iopub.status.idle":"2023-05-14T02:46:25.837591Z","shell.execute_reply.started":"2023-05-14T02:43:02.297637Z","shell.execute_reply":"2023-05-14T02:46:25.835749Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"print([len(i) for i in [train_dict, test_dict, val_dict]])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:46:25.846808Z","iopub.execute_input":"2023-05-14T02:46:25.849921Z","iopub.status.idle":"2023-05-14T02:46:25.862788Z","shell.execute_reply.started":"2023-05-14T02:46:25.849875Z","shell.execute_reply":"2023-05-14T02:46:25.861398Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"[149571, 9000, 1000]\n","output_type":"stream"}]},{"cell_type":"code","source":"target_row","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:46:25.864289Z","iopub.execute_input":"2023-05-14T02:46:25.864665Z","iopub.status.idle":"2023-05-14T02:46:25.873291Z","shell.execute_reply.started":"2023-05-14T02:46:25.864630Z","shell.execute_reply":"2023-05-14T02:46:25.872211Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"[0.0, 0.0, 0.0, 1.0, 1.0, 1.0]"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing.","metadata":{"id":"QCL02vQgxYTO"}},{"cell_type":"code","source":"dir(dataset['train'])\ndataset['train'].__class__\n#https://arrow.apache.org/docs/python/generated/pyarrow.Table.html\nimport pyarrow as pa\ntest_table = pa.Table.from_pandas(pd.DataFrame(test_dict))\ntest_dataset = datasets.arrow_dataset.Dataset(test_table)\n\ntrain_table = pa.Table.from_pandas(pd.DataFrame(train_dict))\ntrain_dataset = datasets.arrow_dataset.Dataset(train_table)\n\nval_table = pa.Table.from_pandas(pd.DataFrame(val_dict))\nval_dataset = datasets.arrow_dataset.Dataset(val_table)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRd1kXQZjYIY","outputId":"8021590c-5607-4a9c-a474-bc57da503c93","execution":{"iopub.status.busy":"2023-05-14T02:46:25.875372Z","iopub.execute_input":"2023-05-14T02:46:25.875946Z","iopub.status.idle":"2023-05-14T02:46:26.674522Z","shell.execute_reply.started":"2023-05-14T02:46:25.875911Z","shell.execute_reply":"2023-05-14T02:46:26.672929Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.__class__\ndataset = datasets.dataset_dict.DatasetDict({'test':test_dataset, \n                                             'train':train_dataset,\n                                            'validation':val_dataset})\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:46:26.676326Z","iopub.execute_input":"2023-05-14T02:46:26.677029Z","iopub.status.idle":"2023-05-14T02:46:26.683024Z","shell.execute_reply.started":"2023-05-14T02:46:26.676990Z","shell.execute_reply":"2023-05-14T02:46:26.681897Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"dataset['train']","metadata":{"execution":{"iopub.status.busy":"2023-05-14T02:46:26.684636Z","iopub.execute_input":"2023-05-14T02:46:26.685355Z","iopub.status.idle":"2023-05-14T02:46:26.698773Z","shell.execute_reply.started":"2023-05-14T02:46:26.685320Z","shell.execute_reply":"2023-05-14T02:46:26.697459Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic', 'text', 'ID'],\n    num_rows: 149571\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's check the first example of the training split:","metadata":{"id":"PgS0wMWExcqP"}},{"cell_type":"code","source":"example = train_dict[0]\nexample","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unjuTtKUjZI3","outputId":"6f1e5051-8272-40f9-ced8-ba17a105e904","execution":{"iopub.status.busy":"2023-05-14T02:46:26.700477Z","iopub.execute_input":"2023-05-14T02:46:26.700869Z","iopub.status.idle":"2023-05-14T02:46:26.711957Z","shell.execute_reply.started":"2023-05-14T02:46:26.700835Z","shell.execute_reply":"2023-05-14T02:46:26.710895Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"{'identity_hate': 0,\n 'insult': 1,\n 'obscene': 1,\n 'severe_toxic': 0,\n 'threat': 0,\n 'toxic': 1,\n 'text': 'you  suck even if you stupid admins checkusers block us and find our ips  we ll always come back for more vandalism  trolling  harrassment  you stupid admins then cry over the fact of the enormous amounts of vandalism harrassment all day and all night because soon we will just take over and wikipedia wouldn t exist anymore  we will never stop vandalizing and harrassing other users like you on wikipedia to make their editing experience worse so they would quit ',\n 'ID': 10000}"},"metadata":{}}]},{"cell_type":"markdown","source":"The dataset consists of tweets, labeled with one or more emotions. \n\nLet's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back.","metadata":{"id":"6DV0Rtetxgd4"}},{"cell_type":"code","source":"labels = [str(label) for label in grouping if label not in ['ID', 'text']]\nid2label = {idx:label for idx, label in enumerate(labels)}\nlabel2id = {label:idx for idx, label in enumerate(labels)}\nlabels[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5vZhQpvkE8s","outputId":"5d513b30-f209-492f-c6ab-245d64a67d40","execution":{"iopub.status.busy":"2023-05-14T02:46:26.716708Z","iopub.execute_input":"2023-05-14T02:46:26.717005Z","iopub.status.idle":"2023-05-14T02:46:26.727432Z","shell.execute_reply.started":"2023-05-14T02:46:26.716981Z","shell.execute_reply":"2023-05-14T02:46:26.726531Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"'identity_hate'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocess data\n\nAs models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n\nWhat's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3).","metadata":{"id":"nJ3Teyjmank2"}},{"cell_type":"code","source":"\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef preprocess_data(examples):\n  # take a batch of texts\n  text = examples[\"text\"]\n  # encode them\n  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n  # add labels\n  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n  # create numpy array of shape (batch_size, num_labels)\n  labels_matrix = np.zeros((len(text), len(labels)))\n  # fill numpy array\n  for idx, label in enumerate(labels):\n    labels_matrix[:, idx] = labels_batch[label]\n\n  encoding[\"labels\"] = labels_matrix.tolist()\n  \n  return encoding","metadata":{"id":"AFWlSsbZaRLc","execution":{"iopub.status.busy":"2023-05-14T02:46:26.728710Z","iopub.execute_input":"2023-05-14T02:46:26.729018Z","iopub.status.idle":"2023-05-14T02:46:26.876916Z","shell.execute_reply.started":"2023-05-14T02:46:26.728989Z","shell.execute_reply":"2023-05-14T02:46:26.875856Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=train_dataset.column_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4ENBTdulBEI","outputId":"02554a1f-4961-461a-bf29-555b8debeabf","execution":{"iopub.status.busy":"2023-05-14T02:46:26.878508Z","iopub.execute_input":"2023-05-14T02:46:26.879183Z","iopub.status.idle":"2023-05-14T02:47:13.361682Z","shell.execute_reply.started":"2023-05-14T02:46:26.879122Z","shell.execute_reply":"2023-05-14T02:47:13.355247Z"},"trusted":true},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3250a5fc43c74a25b7a9d9b448a10805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/150 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4241a13ba7d4473890e9bc572559f4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"619c0eea87f64724adbd50124d0c364a"}},"metadata":{}}]},{"cell_type":"code","source":"example = encoded_dataset['train'][0]\nprint(example.keys())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0enAb0W9o25W","outputId":"55bc5ba6-d169-49c6-f562-bb7ea4143866","execution":{"iopub.status.busy":"2023-05-14T02:47:13.365892Z","iopub.execute_input":"2023-05-14T02:47:13.366368Z","iopub.status.idle":"2023-05-14T02:47:13.375923Z","shell.execute_reply.started":"2023-05-14T02:47:13.366328Z","shell.execute_reply":"2023-05-14T02:47:13.374771Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode(example['input_ids'])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"D0McCtJ8HRJY","outputId":"82fb0336-51a3-40ad-ebc0-65eeb7cf4b6c","execution":{"iopub.status.busy":"2023-05-14T02:47:13.378440Z","iopub.execute_input":"2023-05-14T02:47:13.379022Z","iopub.status.idle":"2023-05-14T02:47:13.400198Z","shell.execute_reply.started":"2023-05-14T02:47:13.378989Z","shell.execute_reply":"2023-05-14T02:47:13.399026Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"'[CLS] you suck even if you stupid admins checkusers block us and find our ips we ll always come back for more vandalism trolling harrassment you stupid admins then cry over the fact of the enormous amounts of vandalism harrassment all day and all night because soon we will just take over and wikipedia wouldn t exist anymore we will never stop vandalizing and harrassing other users like you on wikipedia to make their editing experience worse so they would quit [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"},"metadata":{}}]},{"cell_type":"code","source":"example['labels']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdIvj6WjHeZQ","outputId":"418c14d2-cca3-44e9-d0a2-6ad4ca7a007c","execution":{"iopub.status.busy":"2023-05-14T02:47:13.404796Z","iopub.execute_input":"2023-05-14T02:47:13.405502Z","iopub.status.idle":"2023-05-14T02:47:13.419166Z","shell.execute_reply.started":"2023-05-14T02:47:13.405467Z","shell.execute_reply":"2023-05-14T02:47:13.418069Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"[0.0, 1.0, 1.0, 0.0, 0.0, 1.0]"},"metadata":{}}]},{"cell_type":"code","source":"[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4Dx95t2o6N9","outputId":"3ce6c923-0b45-4743-bc4b-7771d088b03e","execution":{"iopub.status.busy":"2023-05-14T02:47:13.420657Z","iopub.execute_input":"2023-05-14T02:47:13.422617Z","iopub.status.idle":"2023-05-14T02:47:13.431946Z","shell.execute_reply.started":"2023-05-14T02:47:13.422583Z","shell.execute_reply":"2023-05-14T02:47:13.430907Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"['insult', 'obscene', 'toxic']"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). ","metadata":{"id":"HgpKXDfvKBxn"}},{"cell_type":"code","source":"encoded_dataset.set_format(\"torch\")","metadata":{"id":"Lk6Cq9duKBkA","execution":{"iopub.status.busy":"2023-05-14T02:47:13.433598Z","iopub.execute_input":"2023-05-14T02:47:13.434304Z","iopub.status.idle":"2023-05-14T02:47:13.443083Z","shell.execute_reply.started":"2023-05-14T02:47:13.434260Z","shell.execute_reply":"2023-05-14T02:47:13.441821Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"## Define model\n\nHere we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n\nThis is also printed by the warning.\n\nWe set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings.","metadata":{"id":"w5qSmCgWefWs"}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n                                                           problem_type=\"multi_label_classification\", \n                                                           num_labels=len(labels),\n                                                           id2label=id2label,\n                                                           label2id=label2id)\n\n#model = torch.load('Colab_cats_model_202304131403').cuda()                                                           ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XPL1Z_RegBF","outputId":"22994300-8c93-421e-faa4-678d6cc14aab","execution":{"iopub.status.busy":"2023-05-14T02:47:13.445359Z","iopub.execute_input":"2023-05-14T02:47:13.445931Z","iopub.status.idle":"2023-05-14T02:47:16.803304Z","shell.execute_reply.started":"2023-05-14T02:47:13.445897Z","shell.execute_reply":"2023-05-14T02:47:16.802291Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train the model!\n\nWe are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things: \n\n* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1)).","metadata":{"id":"mjJGEXShp7te"}},{"cell_type":"code","source":"batch_size = 16\nmetric_name = \"f1\"","metadata":{"id":"K5a8_vIKqr7P","execution":{"iopub.status.busy":"2023-05-14T02:47:16.807785Z","iopub.execute_input":"2023-05-14T02:47:16.808766Z","iopub.status.idle":"2023-05-14T02:47:16.815344Z","shell.execute_reply.started":"2023-05-14T02:47:16.808713Z","shell.execute_reply":"2023-05-14T02:47:16.813602Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"\n\nargs = TrainingArguments(\n    f\"bert-finetuned-sem_eval-english\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=2,#5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=metric_name,\n    #push_to_hub=True,\n)","metadata":{"id":"dR2GmpvDqbuZ","execution":{"iopub.status.busy":"2023-05-14T02:47:16.818530Z","iopub.execute_input":"2023-05-14T02:47:16.818908Z","iopub.status.idle":"2023-05-14T02:47:16.834883Z","shell.execute_reply.started":"2023-05-14T02:47:16.818870Z","shell.execute_reply":"2023-05-14T02:47:16.833932Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values.","metadata":{"id":"1_v2fPFFJ3-v"}},{"cell_type":"code","source":"\n# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = labels\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {'f1': f1_micro_average,\n               'roc_auc': roc_auc,\n               'accuracy': accuracy}\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, \n            tuple) else p.predictions\n    result = multi_label_metrics(\n        predictions=preds, \n        labels=p.label_ids)\n    return result","metadata":{"id":"797b2WHJqUgZ","execution":{"iopub.status.busy":"2023-05-14T02:47:16.836420Z","iopub.execute_input":"2023-05-14T02:47:16.836826Z","iopub.status.idle":"2023-05-14T02:47:16.845785Z","shell.execute_reply.started":"2023-05-14T02:47:16.836794Z","shell.execute_reply":"2023-05-14T02:47:16.844835Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Let's verify a batch as well as a forward pass:","metadata":{"id":"fxNo4_TsvzDm"}},{"cell_type":"code","source":"encoded_dataset['train'][0]['labels'].type()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IlOgGiojuWwG","outputId":"cd0b2c99-b520-468d-8ffc-c36211b7820a","execution":{"iopub.status.busy":"2023-05-14T02:47:16.854068Z","iopub.execute_input":"2023-05-14T02:47:16.854910Z","iopub.status.idle":"2023-05-14T02:47:16.863350Z","shell.execute_reply.started":"2023-05-14T02:47:16.854875Z","shell.execute_reply":"2023-05-14T02:47:16.862463Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"'torch.FloatTensor'"},"metadata":{}}]},{"cell_type":"code","source":"encoded_dataset['train']['input_ids'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y41Kre_jvD7x","outputId":"b6ca888b-6371-40fb-ab83-3dc24d28320a","execution":{"iopub.status.busy":"2023-05-14T02:47:16.864845Z","iopub.execute_input":"2023-05-14T02:47:16.865511Z","iopub.status.idle":"2023-05-14T02:47:18.006970Z","shell.execute_reply.started":"2023-05-14T02:47:16.865478Z","shell.execute_reply":"2023-05-14T02:47:18.005883Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  2017, 11891,  2130,  2065,  2017,  5236,  4748, 21266,  4638,\n        20330,  2015,  3796,  2149,  1998,  2424,  2256, 12997,  2015,  2057,\n         2222,  2467,  2272,  2067,  2005,  2062,  3158,  9305,  2964, 18792,\n         2075,  5292, 11335,  4757,  3672,  2017,  5236,  4748, 21266,  2059,\n         5390,  2058,  1996,  2755,  1997,  1996,  8216,  8310,  1997,  3158,\n         9305,  2964,  5292, 11335,  4757,  3672,  2035,  2154,  1998,  2035,\n         2305,  2138,  2574,  2057,  2097,  2074,  2202,  2058,  1998, 16948,\n         2876,  1056,  4839,  4902,  2057,  2097,  2196,  2644,  3158,  9305,\n         6026,  1998,  5292, 11335, 18965,  2060,  5198,  2066,  2017,  2006,\n        16948,  2000,  2191,  2037,  9260,  3325,  4788,  2061,  2027,  2052,\n         8046,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"#forward pass\n#outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n#outputs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxWcnZ8ku12V","outputId":"26522911-c3cd-466a-ae2d-d81d23003c23","execution":{"iopub.status.busy":"2023-05-14T02:47:18.011885Z","iopub.execute_input":"2023-05-14T02:47:18.014615Z","iopub.status.idle":"2023-05-14T02:47:18.022126Z","shell.execute_reply.started":"2023-05-14T02:47:18.014557Z","shell.execute_reply":"2023-05-14T02:47:18.021133Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"Let's start training!","metadata":{"id":"f-X2brZcv0X6"}},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"id":"chq_3nUz73ib","execution":{"iopub.status.busy":"2023-05-14T02:47:18.025070Z","iopub.execute_input":"2023-05-14T02:47:18.025527Z","iopub.status.idle":"2023-05-14T02:47:18.165491Z","shell.execute_reply.started":"2023-05-14T02:47:18.025493Z","shell.execute_reply":"2023-05-14T02:47:18.164493Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KXmFds8js6P8","outputId":"66ebb2ab-f93f-48aa-a4dc-36f55f2f8559","execution":{"iopub.status.busy":"2023-05-14T02:47:18.169859Z","iopub.execute_input":"2023-05-14T02:47:18.172801Z","iopub.status.idle":"2023-05-14T03:55:51.960583Z","shell.execute_reply.started":"2023-05-14T02:47:18.172762Z","shell.execute_reply":"2023-05-14T03:55:51.959497Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9350' max='9350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9350/9350 1:08:33, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.039300</td>\n      <td>0.046577</td>\n      <td>0.764579</td>\n      <td>0.860463</td>\n      <td>0.918000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.031800</td>\n      <td>0.048013</td>\n      <td>0.773389</td>\n      <td>0.878200</td>\n      <td>0.914000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=9350, training_loss=0.039535691164394114, metrics={'train_runtime': 4113.7194, 'train_samples_per_second': 72.718, 'train_steps_per_second': 2.273, 'total_flos': 1.9677598514113536e+16, 'train_loss': 0.039535691164394114, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate\n\nAfter training, we evaluate our model on the validation set.","metadata":{"id":"hiloh9eMK91o"}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"cMlebJ83LRYG","outputId":"b18102e7-2198-4beb-c874-d39636f740ed","execution":{"iopub.status.busy":"2023-05-14T03:55:51.964841Z","iopub.execute_input":"2023-05-14T03:55:51.965473Z","iopub.status.idle":"2023-05-14T03:55:57.197878Z","shell.execute_reply.started":"2023-05-14T03:55:51.965436Z","shell.execute_reply":"2023-05-14T03:55:57.195889Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:04]\n    </div>\n    "},"metadata":{}},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.04801326245069504,\n 'eval_f1': 0.7733887733887733,\n 'eval_roc_auc': 0.8781998082849221,\n 'eval_accuracy': 0.914,\n 'eval_runtime': 5.2113,\n 'eval_samples_per_second': 191.892,\n 'eval_steps_per_second': 6.141,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference\n\nLet's test the model on a new sentence:","metadata":{"id":"3nmvJp0pLq-3"}},{"cell_type":"markdown","source":"The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label.","metadata":{"id":"8THm5-XgNHPm"}},{"cell_type":"markdown","source":"To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n\nNext, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example).","metadata":{"id":"DC4XdDaHNVcd"}},{"cell_type":"code","source":"torch.save(model,'Colab_model_{}'.format(datetime.now().strftime('%Y%m%d%H%M')))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:57.263096Z","iopub.execute_input":"2023-05-14T03:55:57.264362Z","iopub.status.idle":"2023-05-14T03:55:57.935237Z","shell.execute_reply.started":"2023-05-14T03:55:57.264329Z","shell.execute_reply":"2023-05-14T03:55:57.932010Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"text = test_all.narratives.tolist()[0]\nre.split(r' |\\:|\\,|\\.|\\;|\\n', text)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:57.940395Z","iopub.execute_input":"2023-05-14T03:55:57.942987Z","iopub.status.idle":"2023-05-14T03:55:57.994768Z","shell.execute_reply.started":"2023-05-14T03:55:57.942929Z","shell.execute_reply":"2023-05-14T03:55:57.992199Z"},"trusted":true},"execution_count":91,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtest_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarratives\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m |\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m,|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m;|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'narratives'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'narratives'","output_type":"error"}]},{"cell_type":"code","source":"#test_all = df_val\nimport re\nlabel_list = []\nfor text in test_all.narratives.tolist():\n    \n    encoding = tokenizer(text,  return_tensors=\"pt\", padding=True, truncation=True,max_length=512, add_special_tokens = True)\n    encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n    #encoding = {i:torch.tensor([encoding[i][0][:512]]) for i in ['input_ids', 'token_type_ids', 'attention_mask']}\n\n    outputs = model(**encoding)\n\n    logits = outputs.logits\n    logits.shape\n\n    # apply sigmoid + threshold\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(logits.squeeze().cpu())\n    predictions = np.zeros(probs.shape)\n    predictions[np.where(probs >= 0.5)] = 1\n    # turn predicted id's into actual label names\n    predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n    label_list.append(predicted_labels)\n    #print(predicted_labels, len(encoding['input_ids'][0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:57.997916Z","iopub.status.idle":"2023-05-14T03:55:57.998870Z","shell.execute_reply.started":"2023-05-14T03:55:57.998614Z","shell.execute_reply":"2023-05-14T03:55:57.998641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainer.model()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.000408Z","iopub.status.idle":"2023-05-14T03:55:58.000891Z","shell.execute_reply.started":"2023-05-14T03:55:58.000648Z","shell.execute_reply":"2023-05-14T03:55:58.000672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.002571Z","iopub.status.idle":"2023-05-14T03:55:58.003036Z","shell.execute_reply.started":"2023-05-14T03:55:58.002795Z","shell.execute_reply":"2023-05-14T03:55:58.002817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = trainer.predict(test_dataset)\nencoding","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.004353Z","iopub.status.idle":"2023-05-14T03:55:58.005407Z","shell.execute_reply.started":"2023-05-14T03:55:58.005110Z","shell.execute_reply":"2023-05-14T03:55:58.005137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmodel(encoding.input_ids.cuda(), encoding.attention_mask.cuda())\na=model(**{\"input_ids\":encoding.input_ids.cuda(), \"token_type_ids\":encoding.token_type_ids.cuda(), \"attention_mask\":encoding.attention_mask.cuda()})\nb=model(**{k: v.to(trainer.model.device) for k,v in encoding.items()})\nprint(a, b)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.006918Z","iopub.status.idle":"2023-05-14T03:55:58.007430Z","shell.execute_reply.started":"2023-05-14T03:55:58.007166Z","shell.execute_reply":"2023-05-14T03:55:58.007192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lookup table for code hierarchy level and column names, corresponding to the c_ and p_ variables below\nlevel_coding_dict = {'cat' : {'coded_as' : 'ProdGroup_x'},\n                     'subcat' : {'coded_as' : 'ProdSubGroup_x'},\n                     'product' : {'coded_as' : 'CPSRMS_Prod_x'},\n                    }\n\ntest_all['positive_'+level_selection] = label_list\ntest_results = test_all","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.008895Z","iopub.status.idle":"2023-05-14T03:55:58.009853Z","shell.execute_reply.started":"2023-05-14T03:55:58.009565Z","shell.execute_reply":"2023-05-14T03:55:58.009590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for lvl_selection in [level_selection]:#, 'subcat', 'product']:\n    level_coding_dict[lvl_selection]['predicted'] = 'positive_' + lvl_selection\n    report_lvl = level_coding_dict[lvl_selection]\n    # use concise variables that are unlikely to be mixed up with other common variables\n    p_ = report_lvl['predicted']\n    c_ = report_lvl['coded_as']\n    print(p_, c_)\n\n    # aggregated predicted product codes are strings, need to convert them to integers\n    # everywhere else they are integers, so this seems like the simplest way\n    if lvl_selection == 'product': \n        newll = []\n        for i in test_results[p_]:\n            temp = []\n            if i!= []:\n                for j in i:\n                    temp.append(int(j))\n            newll.append(temp)    \n        test_results[p_] = newll\n\n    # list comprehension finds pos codes (FPs) from model not in the coded data\n    test_results[p_ + '_FPs'] = [[k for k in i if k not in j] for i,j in zip(test_results[p_], test_results[c_])]\n    # invert by taking out not for true positives TPs\n    test_results[p_ + '_TPs'] = [[k for k in i if k in j] for i,j in zip(test_results[p_], test_results[c_])]\n    # invert the FPs to FNs by switching the sublists j and i (coded as, predicted as)\n    test_results[p_ + '_FNs'] = [[k for k in j if k not in i] for i,j in zip(test_results[p_], test_results[c_])]","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.015269Z","iopub.status.idle":"2023-05-14T03:55:58.015771Z","shell.execute_reply.started":"2023-05-14T03:55:58.015511Z","shell.execute_reply":"2023-05-14T03:55:58.015536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# turn product grouping and coding lookup table LUT into a dictionary\ncats = codeLUT.Group.drop_duplicates().tolist()\nsubcats = codeLUT.SubGroup.drop_duplicates().tolist()\nprods = codeLUT.Product.drop_duplicates().tolist()\n# create dictionary in the format of {group : {subgroup : {product : code}}}\ncode_dict = {}\nprodcode_dict = {}\nfor cat in cats:\n    code_dict[cat] = {}\n    temp = codeLUT[codeLUT.Group == cat]\n    tempsubcats = temp.SubGroup.drop_duplicates().tolist()\n    for subcat in tempsubcats:\n        code_dict[cat][subcat] = {}\n        subtemp = temp[temp.SubGroup == subcat]\n        temp_prods = subtemp.Product.drop_duplicates().tolist()\n        for prod in temp_prods:\n            # {product as key : code as value}\n            # code_dict[cat][subcat][prod] = subtemp[subtemp.Product == prod].Code.tolist()[0]\n            # {code as key : product as value}\n            code_dict[cat][subcat][subtemp[subtemp.Product == prod].Code.tolist()[0]] = prod\n            prodcode_dict[subtemp[subtemp.Product == prod].Code.tolist()[0]] = prod","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.017515Z","iopub.status.idle":"2023-05-14T03:55:58.018032Z","shell.execute_reply.started":"2023-05-14T03:55:58.017760Z","shell.execute_reply":"2023-05-14T03:55:58.017784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_threshold = 0.95 # assume some final precision threshold above which the categories/subcats/products are automatically machine coded\n\nfor lvl_selection in [level_selection]:\n    # set report_clf_lut aside to do precision analysis\n    precision_df = test_results.copy()\n    report_lvl = level_coding_dict[lvl_selection]\n    # use concise variables that are unlikely to be mixed up with other common variables\n    p_ = report_lvl['predicted']\n    c_ = report_lvl['coded_as']\n    print(p_, c_)\n\n    # this is where we get overall precision, recall, and F1 scores for each cat/subcat/product\n    # get precision for all elements in the category list (group, or subgroup, or product)\n    # precision is TP / (TP + FP)\n    precision_df\n    all_pred_clf = []\n    for item in test_results[p_].tolist():\n        [all_pred_clf.append(element) for element in item if element not in all_pred_clf]\n\n    precision_dictionary = {}\n    recall_dictionary = {}\n    F1_dictionary = {}\n    # add the tp/fp/fn data to verify calculations\n    TP_dictionary = {}\n    FP_dictionary = {}\n    FN_dictionary = {}\n    TPFN_dictionary = {}\n    for clf in all_pred_clf:\n        #print(clf)\n        if lvl_selection == 'product': clf = int(clf)\n        # if the product is in or out of the list in the grid cell, it will return True or False\n        tps = [clf in entry for entry in precision_df[p_ + '_TPs'].tolist()]\n        fps = [clf in entry for entry in precision_df[p_ + '_FPs'].tolist()]\n        fns = [clf in entry for entry in precision_df[p_ + '_FNs'].tolist()]\n        tps = sum(tps)# sum of True values is like sum of 1's\n        fps = sum(fps)\n        fns = sum(fns)\n        \n        try: precision = tps/(tps+fps)\n        except: precision = 0\n        \n        try: recall = tps/(tps+fns)# tps+fns is per report. some reports have the same code multiple times, but a classifier can only detect positive or negative, so tps+fns is different from total instances by a tiny amount in some cases\n        except: recall = 0\n\n        try: f1 = (2 * precision * recall) / (precision + recall)\n        except: f1 = 0\n        #print(precision)\n        precision_dictionary[str(clf)] = precision\n        recall_dictionary[str(clf)] = recall\n        F1_dictionary[str(clf)] = f1\n        \n        TP_dictionary[str(clf)] = tps\n        FP_dictionary[str(clf)] = fps\n        FN_dictionary[str(clf)] = fns\n        TPFN_dictionary[str(clf)] = tps + fns\n        \n    # turn the precision results into an output report\n    # resulting in a table with as many rows as the level has (fewer for cats, more for subcats, more rows for prducts)\n    # of category, machine code probability, and frequency of category occurrence\n    # coerce to dataframe format\n    # This is basically a merge operation, but instead of merge, it is sort and find the overlapping set\n    param_dict = {}\n    for dict_item, param in zip([precision_dictionary, recall_dictionary, F1_dictionary, TP_dictionary, FP_dictionary, FN_dictionary, TPFN_dictionary], ['precision', 'recall', 'F1', 'TPs', 'FPs', 'FNs','TPFN_sum']):\n        param_dict[param] = list(dict_item.values())\n    param_df = pd.DataFrame(param_dict)# turn dict to df\n    param_df[lvl_selection] = list(dict_item.keys())# add code columns\n    if lvl_selection == 'product': param_df[lvl_selection] = param_df[lvl_selection].astype(int)# change to compatable integer format\n    valcounts = test_all.explode(c_)[c_].value_counts()# val counts per code\n    valcounts = pd.DataFrame(valcounts.reset_index(level=0))# move code index to column\n    valcounts.columns = [c_, 'frequency_coded_as']# columns named in reverse order, correct this\n    precision_df = param_df.merge(valcounts, left_on=lvl_selection, right_on=c_, how='left')\n    precision_df = precision_df.dropna()\n    # sort so more precise and more frequent values are at the top\n    precision_df = precision_df.sort_values(by=['precision', 'frequency_coded_as'], ascending=[False,False])\n    #print(precision_series)\n    # want to add one more column for the product level summary that converts code to name of code\n    if lvl_selection == 'product':\n        precision_df['product_name'] = [prodcode_dict[int(i)] for i in precision_df[c_].tolist()]\n    \n    # optional filtering by filter list, cats, subcats, and prods all in same list, loop iterates through levels, different batch of precision and recall per level\n    #precision_df = precision_df[ pd.DataFrame(precision_df[c_].tolist()).isin(filter_list).any(1).values]\n    #valcounts = valcounts[ pd.DataFrame(valcounts[c_].tolist()).isin(filter_list).any(1).values]\n    \n    \n    # save table to csv\n    precision_df.to_csv('model_evaluation_summary_{}_{}.csv'.format(c_, datetime.now().strftime('%Y%m%d%H%M')), index=False)\n    #precision_series.head()\n    # get number of records above a threshold\n    t = precision_df[precision_df.precision >= precision_threshold]\n    sum_ = (t.TPFN_sum * t.recall).sum()\n    print(\"{} {} product instances are above the precision threshold out of {} instances, ratio of {}\".format(str(round(sum_)),\n                                                                                                   c_,\n                                                                                                   valcounts.frequency_coded_as.sum(),#precision_df.TPFN_sum.sum()\n                                                                                                   sum_/valcounts.frequency_coded_as.sum()\n                                                                                                             ))  \n    weighted_precision = []\n    for row in range(precision_df.shape[0]):\n        weighted_precision += [precision_df.precision.tolist()[row]] * precision_df.frequency_coded_as.astype(int).tolist()[row]\n    print('Average weighted precision is', np.mean(weighted_precision))\n\nprint('Done.')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T03:55:58.019822Z","iopub.status.idle":"2023-05-14T03:55:58.020399Z","shell.execute_reply.started":"2023-05-14T03:55:58.020124Z","shell.execute_reply":"2023-05-14T03:55:58.020165Z"},"trusted":true},"execution_count":null,"outputs":[]}]}